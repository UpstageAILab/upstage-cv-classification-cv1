{"cells":[{"attachments":{},"cell_type":"markdown","metadata":{"id":"OliaDaX_lwou"},"source":["# **📄 Document type classification baseline code**\n","> 문서 타입 분류 대회에 오신 여러분 환영합니다! 🎉     \n","> 아래 baseline에서는 ResNet 모델을 로드하여, 모델을 학습 및 예측 파일 생성하는 프로세스에 대해 알아보겠습니다.\n","\n","## Contents\n","- Prepare Environments\n","- Import Library & Define Functions\n","- Hyper-parameters\n","- Define transform\n","- Train Model\n","- Inference & Save File\n"]},{"cell_type":"code","execution_count":1,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":8489,"status":"ok","timestamp":1700314558888,"user":{"displayName":"Ynot(송원호)","userId":"16271863862696372773"},"user_tz":-540},"id":"NC8V-D393wY4","outputId":"e9927325-26c4-4b89-9c51-c1d6541388d6"},"outputs":[],"source":["# # 필요한 라이브러리를 설치합니다.\n","# !pip install timm"]},{"attachments":{},"cell_type":"markdown","metadata":{"id":"PXa_FPM73R9f"},"source":["## 2. Import Library & Define Functions\n","* 학습 및 추론에 필요한 라이브러리를 로드합니다.\n","* 학습 및 추론에 필요한 함수와 클래스를 정의합니다."]},{"cell_type":"code","execution_count":1,"metadata":{"executionInfo":{"elapsed":9396,"status":"ok","timestamp":1700314592802,"user":{"displayName":"Ynot(송원호)","userId":"16271863862696372773"},"user_tz":-540},"id":"3BaoIkv5Xwa0"},"outputs":[],"source":["import os\n","import time\n","import random\n","\n","import pickle\n","import shutil\n","import cv2\n","import timm\n","import torch\n","import albumentations as A\n","import pandas as pd\n","import numpy as np\n","import torch.nn as nn\n","from albumentations.pytorch import ToTensorV2\n","from torch.optim import Adam\n","from torchvision import transforms\n","from torch.utils.data import Dataset, DataLoader\n","from PIL import Image\n","from tqdm import tqdm\n","from sklearn.metrics import accuracy_score, f1_score\n","from sklearn.model_selection import train_test_split\n","from matplotlib import pyplot as plt"]},{"cell_type":"code","execution_count":2,"metadata":{},"outputs":[],"source":["# 시드를 고정합니다.\n","SEED = 42\n","os.environ['PYTHONHASHSEED'] = str(SEED)\n","random.seed(SEED)\n","np.random.seed(SEED)\n","torch.manual_seed(SEED)\n","torch.cuda.manual_seed(SEED)\n","torch.cuda.manual_seed_all(SEED)\n","torch.backends.cudnn.benchmark = True"]},{"cell_type":"code","execution_count":3,"metadata":{"executionInfo":{"elapsed":241,"status":"ok","timestamp":1700314772722,"user":{"displayName":"Ynot(송원호)","userId":"16271863862696372773"},"user_tz":-540},"id":"Hyl8oAy6TZAu"},"outputs":[],"source":["# 데이터셋 클래스를 정의합니다.\n","class ImageDataset(Dataset):\n","    def __init__(self, csv, path, transform=None):\n","        self.df = pd.read_csv(csv).values\n","        self.path = path\n","        self.transform = transform\n","\n","    def __len__(self):\n","        return len(self.df)\n","\n","    def __getitem__(self, idx):\n","        name, target = self.df[idx]\n","        img = np.array(Image.open(os.path.join(self.path, name)))\n","        if self.transform:\n","            img = self.transform(image=img)['image']\n","        return img, target"]},{"cell_type":"code","execution_count":4,"metadata":{"executionInfo":{"elapsed":255,"status":"ok","timestamp":1700315066028,"user":{"displayName":"Ynot(송원호)","userId":"16271863862696372773"},"user_tz":-540},"id":"kTECBJfVTbdl"},"outputs":[],"source":["# one epoch 학습을 위한 함수입니다.\n","def train_one_epoch(loader, model, optimizer, loss_fn, device):\n","    model.train()\n","    train_loss = 0\n","    preds_list = []\n","    targets_list = []\n","\n","    pbar = tqdm(loader)\n","    for image, targets in pbar:\n","        image = image.to(device)\n","        targets = targets.to(device)\n","\n","        model.zero_grad(set_to_none=True)\n","\n","        preds = model(image)\n","        loss = loss_fn(preds, targets)\n","        loss.backward()\n","        optimizer.step()\n","\n","        train_loss += loss.item()\n","        preds_list.extend(preds.argmax(dim=1).detach().cpu().numpy())\n","        targets_list.extend(targets.detach().cpu().numpy())\n","\n","        #pbar.set_description(f\"Loss: {loss.item():.4f}\")\n","\n","    train_loss /= len(loader)\n","    train_acc = accuracy_score(targets_list, preds_list)\n","    train_f1 = f1_score(targets_list, preds_list, average='macro')\n","\n","    ret = {\n","        \"train_loss\": train_loss,\n","        \"train_acc\": train_acc,\n","        \"train_f1\": train_f1,\n","    }\n","\n","    return ret"]},{"cell_type":"code","execution_count":5,"metadata":{},"outputs":[],"source":["# one epoch 학습을 위한 함수입니다.\n","def val_one_epoch(loader, model, optimizer, loss_fn, device):\n","    model.eval()\n","    \n","    preds_list = []\n","    targets_list = []\n","\n","    pbar = tqdm(loader)\n","    for image, targets in pbar:\n","        image = image.to(device)\n","        targets = targets.to(device)\n","\n","        model.zero_grad(set_to_none=True)\n","        with torch.no_grad():\n","            preds = model(image)\n","\n","        preds_list.extend(preds.argmax(dim=1).detach().cpu().numpy())\n","        targets_list.extend(targets.detach().cpu().numpy())\n","\n","    train_acc = accuracy_score(targets_list, preds_list)\n","    train_f1 = f1_score(targets_list, preds_list, average='macro')\n","\n","    ret = {\n","        \"train_acc\": train_acc,\n","        \"train_f1\": train_f1,\n","    }\n","\n","    return ret, train_f1"]},{"cell_type":"code","execution_count":6,"metadata":{},"outputs":[],"source":["# csv파일로 분리하기\n","def train_valid_split(csvpath, savepath, epoch, oversample = False):\n","\n","    data = pd.read_csv(csvpath)\n","\n","    x1, x2, _, _ = train_test_split(data,\n","                                    data['target'],\n","                                    test_size = 0.2,\n","                                    shuffle = True,\n","                                    stratify = data['target'],\n","                                    random_state = 42)\n","\n","    if oversample:\n","        weight = x1['target'].value_counts().sort_index()\n","        weight2 = list(map(lambda x: max(weight) - x, weight))\n","        \n","        sample = pd.DataFrame(columns = ['ID', 'target'])\n","        for i in range(17):\n","            sample = pd.concat([sample, x1[x1['target'] == i].sample(weight2[i], replace = True)])\n","\n","        x1 = pd.concat([x1, sample]).reset_index().drop(['index'], axis = 1)\n","\n","\n","        weight = x2['target'].value_counts().sort_index()\n","        weight2 = list(map(lambda x: max(weight) - x, weight))\n","        \n","        sample = pd.DataFrame(columns = ['ID', 'target'])\n","        for i in range(17):\n","            sample = pd.concat([sample, x2[x2['target'] == i].sample(weight2[i], replace = True)])\n","\n","        x2 = pd.concat([x2, sample]).reset_index().drop(['index'], axis = 1)\n","\n","\n","    x1.to_csv(savepath + '/train/' + str(epoch) + '.csv', index = False)\n","    x2.to_csv(savepath + '/valid/' + str(epoch) + '.csv', index = False)"]},{"cell_type":"code","execution_count":7,"metadata":{},"outputs":[],"source":["# mixup 함수 정의\n","def mixup(image1, image2, alpha):\n","    # 이미지 크기 맞추기\n","    image2 = image2.resize(image1.size)\n","    \n","    # mixup 수행\n","    mixed_image = Image.blend(image1, image2, alpha)\n","    return mixed_image"]},{"attachments":{},"cell_type":"markdown","metadata":{"id":"Wjom43UvoXcx"},"source":["## 3. Hyper-parameters\n","* 학습 및 추론에 필요한 하이퍼파라미터들을 정의합니다."]},{"cell_type":"code","execution_count":8,"metadata":{"executionInfo":{"elapsed":436,"status":"ok","timestamp":1700315112439,"user":{"displayName":"Ynot(송원호)","userId":"16271863862696372773"},"user_tz":-540},"id":"KByfAeRmXwYk"},"outputs":[{"name":"stdout","output_type":"stream","text":["cuda\n"]}],"source":["# device\n","device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n","print(device)\n","# data config\n","data_path = '../data/'\n","\n","# model config\n","model_name = 'efficientnet_b0' # 'resnet50' 'efficientnet-b0', ...\n","\n","# training config\n","img_size = 224\n","LR = 1e-3\n","EPOCHS = 100\n","BATCH_SIZE = 32\n","num_workers = 0\n","\n","# early stop count \n","stop_count = 5\n","\n","##################################################################\n","#### image mixup parameter\n","\n","# 이미지가 저장된 폴더 경로\n","folder_path = '../data/rotated_train/'\n","\n","# mixup을 적용할 이미지의 개수\n","num_images_to_mixup = 200\n","\n","# 모델의 특성\n","model_attribute = \"oversampling\"\n"]},{"attachments":{},"cell_type":"markdown","metadata":{"id":"amum-FlIojc6"},"source":["## 4. Define transform\n","* Albumentation 항목을 정의합니다."]},{"cell_type":"code","execution_count":9,"metadata":{"executionInfo":{"elapsed":1,"status":"ok","timestamp":1700315112439,"user":{"displayName":"Ynot(송원호)","userId":"16271863862696372773"},"user_tz":-540},"id":"llh5C7ZKoq2S"},"outputs":[],"source":["# p 함수가 적용될 확률\n","trn_transform = A.Compose([\n","        \n","    A.Resize(height=img_size, width=img_size),\n","    \n","    # 수평,수직 또는 수평 및 수직으로 뒤집는다.\n","    A.Flip(always_apply=False, p=0.3),\n","    \n","    #  -90 ~ 90도 사이로 돌림, 남은 공간은 주변 환경으로 채움 (cv2.BORDER_CONSTAN, cv2.BORDER_REFLECT, cv2.BORDER_REFLECT_101, cv2.BORDER_WRAP)\n","    A.Rotate(limit=180, p=0.8, border_mode=cv2.BORDER_CONSTANT, value=(255, 255, 255)), \n","\n","    # 이미지 크기 조정\n","    A.Resize(height=img_size, width=img_size),\n","\n","    # shift, scale, rotate를 한번에 적용\n","    A.ShiftScaleRotate(shift_limit=0.4, scale_limit=(0.5, 0.9), rotate_limit=180, p=0.3, border_mode=cv2.BORDER_CONSTANT, value=(255, 255, 255)),\n","\n","    # 이미지 크기 조정\n","    A.Resize(height=img_size, width=img_size),\n","\n","    # 밝기와 대비 변경 (대비를 올리면 어두운색은 더 어둡게, 밝은색은 더 밝게)\n","    A.RandomBrightnessContrast(brightness_limit=(-0.1, 0.1), contrast_limit=(-0.2, 0.2), p=0.3),\n","    \n","    # blur_limit가 클수록 더 흐림\n","    A.Blur(p=0.2, blur_limit=(3, 8)),\n","    \n","    # images normalization\n","    A.Normalize(mean=(0.485,0.456,0.406),std=(0.229,0.224,0.225)),\n","\n","    # numpy 이미지나 PIL 이미지를 PyTorch 텐서로 변환\n","    ToTensorV2(),\n","])\n","\n","# val image 변환을 위한 transform 코드\n","val_transform = A.Compose([\n","        \n","    A.Resize(height=img_size, width=img_size),\n","    \n","    # 수평,수직 또는 수평 및 수직으로 뒤집는다.\n","    A.Flip(always_apply=False, p=0.3),\n","    \n","    #  -90 ~ 90도 사이로 돌림, 남은 공간은 주변 환경으로 채움 (cv2.BORDER_CONSTAN, cv2.BORDER_REFLECT, cv2.BORDER_REFLECT_101, cv2.BORDER_WRAP)\n","    A.Rotate(limit=180, p=0.8, border_mode=cv2.BORDER_CONSTANT, value=(255, 255, 255)), \n","\n","    # 이미지 크기 조정\n","    A.Resize(height=img_size, width=img_size),\n","\n","    # shift, scale, rotate를 한번에 적용\n","    A.ShiftScaleRotate(shift_limit=0.4, scale_limit=(0.5, 0.9), rotate_limit=180, p=0.3, border_mode=cv2.BORDER_CONSTANT, value=(255, 255, 255)),\n","\n","    # 이미지 크기 조정\n","    A.Resize(height=img_size, width=img_size),\n","\n","    # 밝기와 대비 변경 (대비를 올리면 어두운색은 더 어둡게, 밝은색은 더 밝게)\n","    A.RandomBrightnessContrast(brightness_limit=(-0.1, 0.1), contrast_limit=(-0.2, 0.2), p=0.3),\n","    \n","    # blur_limit가 클수록 더 흐림\n","    A.Blur(p=0.2, blur_limit=(3, 8)),\n","    \n","    # images normalization\n","    A.Normalize(mean=(0.485,0.456,0.406),std=(0.229,0.224,0.225)),\n","\n","    # numpy 이미지나 PIL 이미지를 PyTorch 텐서로 변환\n","    ToTensorV2(),\n","])\n","\n","# test image 변환을 위한 transform 코드\n","tst_transform = A.Compose([\n","    A.Resize(height=img_size, width=img_size),\n","    A.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n","    ToTensorV2(),\n","])"]},{"attachments":{},"cell_type":"markdown","metadata":{"id":"Nmm5h3J-pXNV"},"source":["## 5. Train Model\n","* 모델을 로드하고, 학습을 진행합니다."]},{"cell_type":"code","execution_count":10,"metadata":{"executionInfo":{"elapsed":870,"status":"ok","timestamp":1700315114067,"user":{"displayName":"Ynot(송원호)","userId":"16271863862696372773"},"user_tz":-540},"id":"FbBgFPsLT-CO"},"outputs":[],"source":["# load model\n","model = timm.create_model(\n","    model_name,\n","    pretrained=True,\n","    num_classes=17\n",").to(device)\n","loss_fn = nn.CrossEntropyLoss()\n","optimizer = Adam(model.parameters(), lr=LR)"]},{"cell_type":"code","execution_count":11,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":8778,"status":"ok","timestamp":1700315122843,"user":{"displayName":"Ynot(송원호)","userId":"16271863862696372773"},"user_tz":-540},"id":"OvIVcSRgUPtS","outputId":"88230bf2-976f-45f6-b3b7-1a2d0ad00548"},"outputs":[{"name":"stderr","output_type":"stream","text":["  0%|          | 0/43 [00:00<?, ?it/s]"]},{"name":"stderr","output_type":"stream","text":["100%|██████████| 43/43 [00:14<00:00,  2.96it/s]\n","100%|██████████| 11/11 [00:03<00:00,  3.55it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Epoch: 0, Loss: 1.5803, Accuracy: 0.5640, F1-Score: 0.5617\n","val, val_Accuracy: 0.6824, val_F1-Score: 0.6776\n"]},{"name":"stderr","output_type":"stream","text":["100%|██████████| 43/43 [00:12<00:00,  3.40it/s]\n","100%|██████████| 11/11 [00:02<00:00,  3.93it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Epoch: 1, Loss: 0.7483, Accuracy: 0.7596, F1-Score: 0.7594\n","val, val_Accuracy: 0.7941, val_F1-Score: 0.7743\n"]},{"name":"stderr","output_type":"stream","text":["100%|██████████| 43/43 [00:12<00:00,  3.39it/s]\n","100%|██████████| 11/11 [00:02<00:00,  3.91it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Epoch: 2, Loss: 0.5967, Accuracy: 0.8088, F1-Score: 0.8061\n","val, val_Accuracy: 0.7559, val_F1-Score: 0.7553\n"]},{"name":"stderr","output_type":"stream","text":["100%|██████████| 43/43 [00:12<00:00,  3.39it/s]\n","100%|██████████| 11/11 [00:02<00:00,  3.91it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Epoch: 3, Loss: 0.4427, Accuracy: 0.8368, F1-Score: 0.8370\n","val, val_Accuracy: 0.8000, val_F1-Score: 0.7959\n"]},{"name":"stderr","output_type":"stream","text":["100%|██████████| 43/43 [00:12<00:00,  3.39it/s]\n","100%|██████████| 11/11 [00:02<00:00,  3.91it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Epoch: 4, Loss: 0.3872, Accuracy: 0.8691, F1-Score: 0.8687\n","val, val_Accuracy: 0.8353, val_F1-Score: 0.8331\n"]},{"name":"stderr","output_type":"stream","text":["100%|██████████| 43/43 [00:12<00:00,  3.41it/s]\n","100%|██████████| 11/11 [00:02<00:00,  3.90it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Epoch: 5, Loss: 0.3573, Accuracy: 0.8787, F1-Score: 0.8790\n","val, val_Accuracy: 0.8529, val_F1-Score: 0.8541\n"]},{"name":"stderr","output_type":"stream","text":["100%|██████████| 43/43 [00:12<00:00,  3.39it/s]\n","100%|██████████| 11/11 [00:02<00:00,  3.92it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Epoch: 6, Loss: 0.3189, Accuracy: 0.8963, F1-Score: 0.8966\n","val, val_Accuracy: 0.8294, val_F1-Score: 0.8256\n"]},{"name":"stderr","output_type":"stream","text":["100%|██████████| 43/43 [00:12<00:00,  3.39it/s]\n","100%|██████████| 11/11 [00:02<00:00,  3.91it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Epoch: 7, Loss: 0.2586, Accuracy: 0.9081, F1-Score: 0.9075\n","val, val_Accuracy: 0.8235, val_F1-Score: 0.8214\n"]},{"name":"stderr","output_type":"stream","text":["100%|██████████| 43/43 [00:12<00:00,  3.38it/s]\n","100%|██████████| 11/11 [00:02<00:00,  3.93it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Epoch: 8, Loss: 0.2753, Accuracy: 0.9169, F1-Score: 0.9167\n","val, val_Accuracy: 0.8382, val_F1-Score: 0.8283\n"]},{"name":"stderr","output_type":"stream","text":["100%|██████████| 43/43 [00:12<00:00,  3.39it/s]\n","100%|██████████| 11/11 [00:02<00:00,  3.90it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Epoch: 9, Loss: 0.2548, Accuracy: 0.9184, F1-Score: 0.9189\n","val, val_Accuracy: 0.8471, val_F1-Score: 0.8427\n"]},{"name":"stderr","output_type":"stream","text":["100%|██████████| 43/43 [00:12<00:00,  3.39it/s]\n","100%|██████████| 11/11 [00:02<00:00,  3.92it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Epoch: 10, Loss: 0.1966, Accuracy: 0.9316, F1-Score: 0.9309\n","val, val_Accuracy: 0.8647, val_F1-Score: 0.8623\n"]},{"name":"stderr","output_type":"stream","text":["100%|██████████| 43/43 [00:12<00:00,  3.39it/s]\n","100%|██████████| 11/11 [00:02<00:00,  3.93it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Epoch: 11, Loss: 0.2482, Accuracy: 0.9206, F1-Score: 0.9202\n","val, val_Accuracy: 0.8206, val_F1-Score: 0.8180\n"]},{"name":"stderr","output_type":"stream","text":["100%|██████████| 43/43 [00:12<00:00,  3.39it/s]\n","100%|██████████| 11/11 [00:02<00:00,  3.91it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Epoch: 12, Loss: 0.2576, Accuracy: 0.9147, F1-Score: 0.9153\n","val, val_Accuracy: 0.8588, val_F1-Score: 0.8605\n"]},{"name":"stderr","output_type":"stream","text":["100%|██████████| 43/43 [00:12<00:00,  3.39it/s]\n","100%|██████████| 11/11 [00:02<00:00,  3.92it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Epoch: 13, Loss: 0.2273, Accuracy: 0.9257, F1-Score: 0.9255\n","val, val_Accuracy: 0.8471, val_F1-Score: 0.8413\n"]},{"name":"stderr","output_type":"stream","text":["100%|██████████| 43/43 [00:12<00:00,  3.36it/s]\n","100%|██████████| 11/11 [00:02<00:00,  3.80it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Epoch: 14, Loss: 0.2496, Accuracy: 0.9169, F1-Score: 0.9168\n","val, val_Accuracy: 0.8529, val_F1-Score: 0.8515\n"]},{"name":"stderr","output_type":"stream","text":["100%|██████████| 43/43 [00:12<00:00,  3.39it/s]\n","100%|██████████| 11/11 [00:02<00:00,  3.81it/s]"]},{"name":"stdout","output_type":"stream","text":["Epoch: 15, Loss: 0.2211, Accuracy: 0.9279, F1-Score: 0.9279\n","val, val_Accuracy: 0.8382, val_F1-Score: 0.8350\n","best epoch: 10, best f1 score: 0.8622543478735559\n"]},{"name":"stderr","output_type":"stream","text":["\n"]}],"source":["# ---------- 변수 건들면 안돼\n","best_epoch = 0\n","best_f1_score = 0\n","stop_early_count = 0\n","\n","for epoch in range(EPOCHS): # EPOCHS\n","    \n","   # early stopping 적용\n","   if stop_early_count == stop_count:\n","      break\n","    \n","   # csv 파일로 분리하기\n","   train_valid_split('../data/train_label_adj.csv',\n","                     '../data/EfficientNet-B0_split/',\n","                     epoch, oversample = True)\n","    \n","   # Dataset 정의\n","   trn_dataset = ImageDataset(\n","      \"../data/EfficientNet-B0_split/train/\" + str(epoch) + \".csv\",\n","      \"../data/train/\",\n","      transform=trn_transform\n","   )\n","\n","   # val _ data만듬\n","   val_dataset = ImageDataset(\n","      \"../data/EfficientNet-B0_split/valid/\" + str(epoch) + \".csv\",\n","      \"../data/train/\",\n","      transform = val_transform\n","   )\n","   \n","   # DataLoader 정의\n","   trn_loader = DataLoader(\n","      trn_dataset,\n","      batch_size=BATCH_SIZE,\n","      shuffle=True,\n","      num_workers=num_workers,\n","      pin_memory=True,\n","      drop_last=False\n","   )\n","\n","   val_loader = DataLoader(\n","      val_dataset,\n","      batch_size=BATCH_SIZE,\n","      shuffle=True,\n","      num_workers=num_workers,\n","      pin_memory=True,\n","      drop_last=False\n","   )\n","\n","   # train \n","   ret = train_one_epoch(trn_loader, model, optimizer, loss_fn, device=device)\n","\n","   # valid\n","   ret2, _train_f1 = val_one_epoch(val_loader, model, optimizer, loss_fn, device=device)\n","   \n","   # 보여지는 부분\n","   print(f\"Epoch: {epoch}, Loss: {ret['train_loss']:.4f}, Accuracy: {ret['train_acc']:.4f}, F1-Score: {ret['train_f1']:.4f}\")\n","   print(f\"val, val_Accuracy: {ret2['train_acc']:.4f}, val_F1-Score: {ret2['train_f1']:.4f}\")\n","   \n","   # f1-score을 비교\n","   if _train_f1 > best_f1_score:\n","      stop_early_count = 0\n","      best_epoch = epoch\n","      best_f1_score = _train_f1\n","      # 학습된 모델을 저장합니다. Pickle 라이브러리를 이용하겠습니다.\n","      with open('../efficientnet-b0/model_epoch' + str(epoch) + model_attribute + '.pkl', 'wb') as f:\n","         pickle.dump(model, f)\n","      \n","   else:\n","      stop_early_count += 1\n","\n","print(f'best epoch: {best_epoch}, best f1 score: {best_f1_score}')"]},{"attachments":{},"cell_type":"markdown","metadata":{"id":"lkwxRXoBpbaX"},"source":["# 6. Inference & Save File\n","* 테스트 이미지에 대한 추론을 진행하고, 결과 파일을 저장합니다."]},{"cell_type":"code","execution_count":12,"metadata":{},"outputs":[],"source":["# test set\n","tst_dataset = ImageDataset(\n","    \"../data/sample_submission.csv\",\n","    \"../data/test/\",\n","    transform=tst_transform\n",")"]},{"cell_type":"code","execution_count":13,"metadata":{},"outputs":[],"source":["# test loader\n","tst_loader = DataLoader(\n","    tst_dataset,\n","    batch_size=BATCH_SIZE,\n","    shuffle=False,\n","    num_workers=0,\n","    pin_memory=True\n",")"]},{"cell_type":"code","execution_count":16,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":12776,"status":"ok","timestamp":1700315185336,"user":{"displayName":"Ynot(송원호)","userId":"16271863862696372773"},"user_tz":-540},"id":"uRYe6jlPU_Om","outputId":"2a08690c-9ffe-418d-8679-eb9280147110"},"outputs":[{"name":"stderr","output_type":"stream","text":["  0%|          | 0/99 [00:00<?, ?it/s]"]},{"name":"stderr","output_type":"stream","text":["100%|██████████| 99/99 [00:25<00:00,  3.82it/s]\n"]}],"source":["# 저장된 모델을 불러옵니다.\n","with open('../efficientnet-b0/model_epoch' + str(best_epoch) + model_attribute + '.pkl', 'rb') as f:\n","    model = pickle.load(f)\n","    \n","preds_list = []\n","\n","model.eval()\n","for image, _ in tqdm(tst_loader):\n","    image = image.to(device)\n","\n","    with torch.no_grad():\n","        preds = model(image)\n","    preds_list.extend(preds.argmax(dim=1).detach().cpu().numpy())"]},{"cell_type":"code","execution_count":17,"metadata":{"executionInfo":{"elapsed":282,"status":"ok","timestamp":1700315216829,"user":{"displayName":"Ynot(송원호)","userId":"16271863862696372773"},"user_tz":-540},"id":"aClN7Qi7VZoh"},"outputs":[],"source":["pred_df = pd.DataFrame(tst_dataset.df, columns=['ID', 'target'])\n","pred_df['target'] = preds_list"]},{"cell_type":"code","execution_count":19,"metadata":{"executionInfo":{"elapsed":1,"status":"ok","timestamp":1700315238836,"user":{"displayName":"Ynot(송원호)","userId":"16271863862696372773"},"user_tz":-540},"id":"VDBXQqAzVvLY"},"outputs":[],"source":["sample_submission_df = pd.read_csv(\"../data/sample_submission.csv\")\n","assert (sample_submission_df['ID'] == pred_df['ID']).all()"]},{"cell_type":"code","execution_count":20,"metadata":{"executionInfo":{"elapsed":317,"status":"ok","timestamp":1700315244710,"user":{"displayName":"Ynot(송원호)","userId":"16271863862696372773"},"user_tz":-540},"id":"ePx2vCELVnuS"},"outputs":[],"source":["pred_df.to_csv(\"../data/pred.csv\", index=False)"]},{"cell_type":"code","execution_count":21,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":206},"executionInfo":{"elapsed":353,"status":"ok","timestamp":1700315247734,"user":{"displayName":"Ynot(송원호)","userId":"16271863862696372773"},"user_tz":-540},"id":"9yMO8s6GqAwZ","outputId":"9a30616f-f0ea-439f-a906-dd806737ce00"},"outputs":[{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>ID</th>\n","      <th>target</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>0008fdb22ddce0ce.jpg</td>\n","      <td>2</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>00091bffdffd83de.jpg</td>\n","      <td>6</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>00396fbc1f6cc21d.jpg</td>\n","      <td>5</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>00471f8038d9c4b6.jpg</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>00901f504008d884.jpg</td>\n","      <td>2</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["                     ID  target\n","0  0008fdb22ddce0ce.jpg       2\n","1  00091bffdffd83de.jpg       6\n","2  00396fbc1f6cc21d.jpg       5\n","3  00471f8038d9c4b6.jpg       0\n","4  00901f504008d884.jpg       2"]},"execution_count":21,"metadata":{},"output_type":"execute_result"}],"source":["pred_df.head()"]}],"metadata":{"accelerator":"GPU","colab":{"provenance":[]},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.13"}},"nbformat":4,"nbformat_minor":0}
