{"cells":[{"attachments":{},"cell_type":"markdown","metadata":{"id":"OliaDaX_lwou"},"source":["# **📄 Document type classification baseline code**\n","> 문서 타입 분류 대회에 오신 여러분 환영합니다! 🎉     \n","> 아래 baseline에서는 ResNet 모델을 로드하여, 모델을 학습 및 예측 파일 생성하는 프로세스에 대해 알아보겠습니다.\n","\n","## Contents\n","- Prepare Environments\n","- Import Library & Define Functions\n","- Hyper-parameters\n","- Load Data\n","- Train Model\n","- Inference & Save File\n"]},{"attachments":{},"cell_type":"markdown","metadata":{"id":"zkH9T_86lDSS"},"source":["## 1. Prepare Environments\n","\n","* 데이터 로드를 위한 구글 드라이브를 마운트합니다.\n","* 필요한 라이브러리를 설치합니다."]},{"cell_type":"markdown","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":21945,"status":"ok","timestamp":1700314517484,"user":{"displayName":"Ynot(송원호)","userId":"16271863862696372773"},"user_tz":-540},"id":"pUjnEto4gIZm","outputId":"0999f10c-e1ff-428c-995b-481eec8a0b58","tags":["parameters"]},"source":["# # 구글 드라이브 마운트, Colab을 이용하지 않는다면 패스해도 됩니다.\n","# from google.colab import drive\n","# drive.mount('/gdrive', force_remount=True)\n","# drive.mount('/content/drive')"]},{"cell_type":"markdown","metadata":{"executionInfo":{"elapsed":7640,"status":"ok","timestamp":1700314537985,"user":{"displayName":"Ynot(송원호)","userId":"16271863862696372773"},"user_tz":-540},"id":"5lFQ-gpjnN_m"},"source":["# # 구글 드라이브에 업로드된 대회 데이터를 압축 해제하고 로컬에 저장합니다.\n","# !tar -xvf drive/MyDrive/datasets_fin.tar > /dev/null"]},{"cell_type":"code","execution_count":3,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":8489,"status":"ok","timestamp":1700314558888,"user":{"displayName":"Ynot(송원호)","userId":"16271863862696372773"},"user_tz":-540},"id":"NC8V-D393wY4","outputId":"e9927325-26c4-4b89-9c51-c1d6541388d6"},"outputs":[{"name":"stdout","output_type":"stream","text":["Requirement already satisfied: timm in /opt/conda/lib/python3.10/site-packages (0.9.12)\n","Requirement already satisfied: torch>=1.7 in /opt/conda/lib/python3.10/site-packages (from timm) (2.1.0)\n","Requirement already satisfied: torchvision in /opt/conda/lib/python3.10/site-packages (from timm) (0.16.0)\n","Requirement already satisfied: pyyaml in /opt/conda/lib/python3.10/site-packages (from timm) (6.0)\n","Requirement already satisfied: huggingface-hub in /opt/conda/lib/python3.10/site-packages (from timm) (0.19.4)\n","Requirement already satisfied: safetensors in /opt/conda/lib/python3.10/site-packages (from timm) (0.4.1)\n","Requirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from torch>=1.7->timm) (3.9.0)\n","Requirement already satisfied: typing-extensions in /opt/conda/lib/python3.10/site-packages (from torch>=1.7->timm) (4.7.1)\n","Requirement already satisfied: sympy in /opt/conda/lib/python3.10/site-packages (from torch>=1.7->timm) (1.11.1)\n","Requirement already satisfied: networkx in /opt/conda/lib/python3.10/site-packages (from torch>=1.7->timm) (3.1)\n","Requirement already satisfied: jinja2 in /opt/conda/lib/python3.10/site-packages (from torch>=1.7->timm) (3.1.2)\n","Requirement already satisfied: fsspec in /opt/conda/lib/python3.10/site-packages (from torch>=1.7->timm) (2023.9.2)\n","Requirement already satisfied: requests in /opt/conda/lib/python3.10/site-packages (from huggingface-hub->timm) (2.31.0)\n","Requirement already satisfied: tqdm>=4.42.1 in /opt/conda/lib/python3.10/site-packages (from huggingface-hub->timm) (4.65.0)\n","Requirement already satisfied: packaging>=20.9 in /opt/conda/lib/python3.10/site-packages (from huggingface-hub->timm) (23.1)\n","Requirement already satisfied: numpy in /opt/conda/lib/python3.10/site-packages (from torchvision->timm) (1.26.0)\n","Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /opt/conda/lib/python3.10/site-packages (from torchvision->timm) (9.4.0)\n","Requirement already satisfied: MarkupSafe>=2.0 in /opt/conda/lib/python3.10/site-packages (from jinja2->torch>=1.7->timm) (2.1.1)\n","Requirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests->huggingface-hub->timm) (2.0.4)\n","Requirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests->huggingface-hub->timm) (3.4)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests->huggingface-hub->timm) (1.26.16)\n","Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests->huggingface-hub->timm) (2023.7.22)\n","Requirement already satisfied: mpmath>=0.19 in /opt/conda/lib/python3.10/site-packages (from sympy->torch>=1.7->timm) (1.3.0)\n","\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n","\u001b[0m"]}],"source":["# 필요한 라이브러리를 설치합니다.\n","%pip install timm"]},{"attachments":{},"cell_type":"markdown","metadata":{"id":"PXa_FPM73R9f"},"source":["## 2. Import Library & Define Functions\n","* 학습 및 추론에 필요한 라이브러리를 로드합니다.\n","* 학습 및 추론에 필요한 함수와 클래스를 정의합니다."]},{"cell_type":"code","execution_count":1,"metadata":{"executionInfo":{"elapsed":9396,"status":"ok","timestamp":1700314592802,"user":{"displayName":"Ynot(송원호)","userId":"16271863862696372773"},"user_tz":-540},"id":"3BaoIkv5Xwa0"},"outputs":[],"source":["import os\n","import time\n","import random\n","\n","import timm\n","import torch\n","import albumentations as A\n","import pandas as pd\n","import numpy as np\n","import torch.nn as nn\n","from albumentations.pytorch import ToTensorV2\n","from torch.optim import Adam\n","from torchvision import transforms\n","from torch.utils.data import Dataset, DataLoader\n","from PIL import Image\n","from tqdm import tqdm\n","from sklearn.metrics import accuracy_score, f1_score"]},{"cell_type":"code","execution_count":2,"metadata":{},"outputs":[],"source":["# 시드를 고정합니다.\n","SEED = 42\n","os.environ['PYTHONHASHSEED'] = str(SEED)\n","random.seed(SEED)\n","np.random.seed(SEED)\n","torch.manual_seed(SEED)\n","torch.cuda.manual_seed(SEED)\n","torch.cuda.manual_seed_all(SEED)\n","torch.backends.cudnn.benchmark = True"]},{"cell_type":"code","execution_count":10,"metadata":{"executionInfo":{"elapsed":241,"status":"ok","timestamp":1700314772722,"user":{"displayName":"Ynot(송원호)","userId":"16271863862696372773"},"user_tz":-540},"id":"Hyl8oAy6TZAu"},"outputs":[],"source":["# 데이터셋 클래스를 정의합니다.\n","class ImageDataset(Dataset):\n","    def __init__(self, csv, path, transform=None):\n","        self.df = pd.read_csv(csv).values\n","        self.path = path\n","        self.transform = transform\n","\n","    def __len__(self):\n","        return len(self.df)\n","\n","    def __getitem__(self, idx):\n","        name, target = self.df[idx]\n","        img = np.array(Image.open(os.path.join(self.path, name)))\n","        if self.transform:\n","            img = self.transform(image=img)['image']\n","        return img, int(target)"]},{"cell_type":"code","execution_count":11,"metadata":{"executionInfo":{"elapsed":255,"status":"ok","timestamp":1700315066028,"user":{"displayName":"Ynot(송원호)","userId":"16271863862696372773"},"user_tz":-540},"id":"kTECBJfVTbdl"},"outputs":[],"source":["# one epoch 학습을 위한 함수입니다.\n","def train_one_epoch(loader, model, optimizer, loss_fn, device):\n","    model.train()\n","    train_loss = 0\n","    preds_list = []\n","    targets_list = []\n","\n","    pbar = tqdm(loader)\n","    for image, targets in pbar:\n","        image = image.to(device)\n","        targets = targets.to(device)\n","\n","        model.zero_grad(set_to_none=True)\n","\n","        preds = model(image)\n","        loss = loss_fn(preds, targets)\n","        loss.backward()\n","        optimizer.step()\n","\n","        train_loss += loss.item()\n","        preds_list.extend(preds.argmax(dim=1).detach().cpu().numpy())\n","        targets_list.extend(targets.detach().cpu().numpy())\n","\n","        pbar.set_description(f\"Loss: {loss.item():.4f}\")\n","\n","    train_loss /= len(loader)\n","    train_acc = accuracy_score(targets_list, preds_list)\n","    train_f1 = f1_score(targets_list, preds_list, average='macro')\n","\n","    ret = {\n","        \"train_loss\": train_loss,\n","        \"train_acc\": train_acc,\n","        \"train_f1\": train_f1,\n","    }\n","\n","    return ret"]},{"attachments":{},"cell_type":"markdown","metadata":{"id":"Wjom43UvoXcx"},"source":["## 3. Hyper-parameters\n","* 학습 및 추론에 필요한 하이퍼파라미터들을 정의합니다."]},{"cell_type":"code","execution_count":12,"metadata":{"executionInfo":{"elapsed":436,"status":"ok","timestamp":1700315112439,"user":{"displayName":"Ynot(송원호)","userId":"16271863862696372773"},"user_tz":-540},"id":"KByfAeRmXwYk"},"outputs":[],"source":["# device\n","device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n","\n","# data config\n","data_path = 'data/'\n","\n","# model config\n","model_name = 'resnet50' # 'resnet50' 'efficientnet-b0', ...# vgg16\n","\n","# training config\n","img_size = 256\n","LR = 1e-3\n","EPOCHS = 30\n","BATCH_SIZE = 32\n","num_workers = 0"]},{"attachments":{},"cell_type":"markdown","metadata":{"id":"amum-FlIojc6"},"source":["## 4. Load Data\n","* 학습, 테스트 데이터셋과 로더를 정의합니다."]},{"cell_type":"code","execution_count":13,"metadata":{"executionInfo":{"elapsed":1,"status":"ok","timestamp":1700315112439,"user":{"displayName":"Ynot(송원호)","userId":"16271863862696372773"},"user_tz":-540},"id":"llh5C7ZKoq2S"},"outputs":[],"source":["# augmentation을 위한 transform 코드\n","trn_transform = A.Compose([\n","    # 이미지 크기 조정\n","    A.Resize(height=img_size, width=img_size),\n","    # images normalization\n","    A.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n","    # numpy 이미지나 PIL 이미지를 PyTorch 텐서로 변환\n","    ToTensorV2(),\n","])\n","\n","# test image 변환을 위한 transform 코드\n","tst_transform = A.Compose([\n","    A.Resize(height=img_size, width=img_size),\n","    A.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n","    ToTensorV2(),\n","])"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":3,"status":"ok","timestamp":1700315112808,"user":{"displayName":"Ynot(송원호)","userId":"16271863862696372773"},"user_tz":-540},"id":"INxdmsStop2L","outputId":"49f0d412-8ce6-4d2f-ae78-d5cf3d056340"},"outputs":[{"name":"stdout","output_type":"stream","text":["1570 3140\n"]}],"source":["# Dataset 정의\n","# trn_dataset = ImageDataset(\n","#     \"data/train.csv\",\n","#     \"data/train_2/\",\n","#     transform=trn_transform\n","# )\n","tst_dataset = ImageDataset(\n","    \"data/sample_submission.csv\",\n","    \"data/test/\",\n","    transform=tst_transform\n",")\n","print(len(tst_dataset)) # len(trn_dataset),"]},{"cell_type":"code","execution_count":null,"metadata":{"executionInfo":{"elapsed":1,"status":"ok","timestamp":1700315112808,"user":{"displayName":"Ynot(송원호)","userId":"16271863862696372773"},"user_tz":-540},"id":"_sO03fWaQj1h"},"outputs":[],"source":["# DataLoader 정의\n","# trn_loader = DataLoader(\n","#     trn_dataset,\n","#     batch_size=BATCH_SIZE,\n","#     shuffle=True,\n","#     num_workers=num_workers,\n","#     pin_memory=True,\n","#     drop_last=False\n","# )\n","tst_loader = DataLoader(\n","    tst_dataset,\n","    batch_size=BATCH_SIZE,\n","    shuffle=False,\n","    num_workers=0,\n","    pin_memory=True\n",")"]},{"attachments":{},"cell_type":"markdown","metadata":{"id":"Nmm5h3J-pXNV"},"source":["## 5. Train Model\n","* 모델을 로드하고, 학습을 진행합니다."]},{"cell_type":"code","execution_count":78,"metadata":{},"outputs":[],"source":["from sklearn.model_selection import StratifiedKFold\n","from torch.utils.data import Subset\n","from sklearn.preprocessing import LabelEncoder\n","\n","# Define the number of splits\n","n_splits = 5  # You can adjust the number of splits as needed\n","\n","# Define StratifiedKFold\n","skf = StratifiedKFold(n_splits=n_splits, shuffle=True, random_state=42)\n","\n","# Define dataset and loaders\n","dataset = ImageDataset(\"data/train.csv\", \"data/train_2/\", transform=trn_transform)\n","label_encoder = LabelEncoder()\n","\n","# Dictionary to store results\n","results = {\n","    \"train_loss\": [],\n","    \"train_acc\": [],\n","    \"train_f1\": []\n","}\n","\n","# Iterate through folds\n","X = dataset.df[:,0]  # 이미지 데이터\n","y = dataset.df[:,1]  # 타겟 데이터\n","y = y.astype(int)\n","# ValueError: Supported target types are: ('binary', 'multiclass'). Got 'unknown' instead.\n","#y = label_encoder.fit_transform(y) # label encoder 안해주면, error나옴"]},{"cell_type":"code","execution_count":79,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":8778,"status":"ok","timestamp":1700315122843,"user":{"displayName":"Ynot(송원호)","userId":"16271863862696372773"},"user_tz":-540},"id":"OvIVcSRgUPtS","outputId":"88230bf2-976f-45f6-b3b7-1a2d0ad00548"},"outputs":[{"name":"stdout","output_type":"stream","text":["Fold 1/5\n","Epoch 1/30\n"]},{"name":"stderr","output_type":"stream","text":["Loss: 0.6347: 100%|██████████| 40/40 [00:07<00:00,  5.06it/s]\n"]},{"name":"stdout","output_type":"stream","text":["train_loss: 1.7818\n","train_acc: 0.5072\n","train_f1: 0.4928\n","\n","Epoch 2/30\n"]},{"name":"stderr","output_type":"stream","text":["Loss: 0.5295: 100%|██████████| 40/40 [00:07<00:00,  5.05it/s]\n"]},{"name":"stdout","output_type":"stream","text":["train_loss: 0.4084\n","train_acc: 0.8543\n","train_f1: 0.8409\n","\n","Fold 2/5\n","Epoch 1/30\n"]},{"name":"stderr","output_type":"stream","text":["Loss: 0.9502: 100%|██████████| 40/40 [00:07<00:00,  5.08it/s]\n"]},{"name":"stdout","output_type":"stream","text":["train_loss: 1.8552\n","train_acc: 0.5088\n","train_f1: 0.4666\n","\n","Epoch 2/30\n"]},{"name":"stderr","output_type":"stream","text":["Loss: 0.3201: 100%|██████████| 40/40 [00:07<00:00,  5.06it/s]\n"]},{"name":"stdout","output_type":"stream","text":["train_loss: 0.4138\n","train_acc: 0.8662\n","train_f1: 0.8466\n","\n","Fold 3/5\n","Epoch 1/30\n"]},{"name":"stderr","output_type":"stream","text":["Loss: 1.0810: 100%|██████████| 40/40 [00:07<00:00,  5.08it/s]\n"]},{"name":"stdout","output_type":"stream","text":["train_loss: 1.9083\n","train_acc: 0.5135\n","train_f1: 0.4728\n","\n","Epoch 2/30\n"]},{"name":"stderr","output_type":"stream","text":["Loss: 0.5634: 100%|██████████| 40/40 [00:07<00:00,  5.04it/s]\n"]},{"name":"stdout","output_type":"stream","text":["train_loss: 0.4209\n","train_acc: 0.8479\n","train_f1: 0.8240\n","\n","Fold 4/5\n","Epoch 1/30\n"]},{"name":"stderr","output_type":"stream","text":["Loss: 2.2137: 100%|██████████| 40/40 [00:07<00:00,  5.05it/s]\n"]},{"name":"stdout","output_type":"stream","text":["train_loss: 1.8157\n","train_acc: 0.5454\n","train_f1: 0.4778\n","\n","Epoch 2/30\n"]},{"name":"stderr","output_type":"stream","text":["Loss: 0.2387:  90%|█████████ | 36/40 [00:07<00:00,  4.86it/s]\n"]},{"ename":"KeyboardInterrupt","evalue":"","output_type":"error","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","Cell \u001b[0;32mIn[79], line 39\u001b[0m\n\u001b[1;32m     36\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mEpoch \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mepoch\u001b[38;5;250m \u001b[39m\u001b[38;5;241m+\u001b[39m\u001b[38;5;250m \u001b[39m\u001b[38;5;241m1\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m/\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mEPOCHS\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     38\u001b[0m \u001b[38;5;66;03m# Train one epoch\u001b[39;00m\n\u001b[0;32m---> 39\u001b[0m train_ret \u001b[38;5;241m=\u001b[39m \u001b[43mtrain_one_epoch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrain_loader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptimizer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mloss_fn\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     41\u001b[0m \u001b[38;5;66;03m# Log train results\u001b[39;00m\n\u001b[1;32m     42\u001b[0m train_log \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m\n","Cell \u001b[0;32mIn[11], line 15\u001b[0m, in \u001b[0;36mtrain_one_epoch\u001b[0;34m(loader, model, optimizer, loss_fn, device)\u001b[0m\n\u001b[1;32m     11\u001b[0m targets \u001b[38;5;241m=\u001b[39m targets\u001b[38;5;241m.\u001b[39mto(device)\n\u001b[1;32m     13\u001b[0m model\u001b[38;5;241m.\u001b[39mzero_grad(set_to_none\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[0;32m---> 15\u001b[0m preds \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mimage\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     16\u001b[0m loss \u001b[38;5;241m=\u001b[39m loss_fn(preds, targets)\n\u001b[1;32m     17\u001b[0m loss\u001b[38;5;241m.\u001b[39mbackward()\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torch/nn/modules/module.py:1518\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1516\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1518\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torch/nn/modules/module.py:1527\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1522\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1523\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1524\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1525\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1526\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1527\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1529\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1530\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/timm/models/resnet.py:578\u001b[0m, in \u001b[0;36mResNet.forward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m    577\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, x: torch\u001b[38;5;241m.\u001b[39mTensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m torch\u001b[38;5;241m.\u001b[39mTensor:\n\u001b[0;32m--> 578\u001b[0m     x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mforward_features\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    579\u001b[0m     x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mforward_head(x)\n\u001b[1;32m    580\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m x\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/timm/models/resnet.py:567\u001b[0m, in \u001b[0;36mResNet.forward_features\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m    565\u001b[0m     x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlayer1(x)\n\u001b[1;32m    566\u001b[0m     x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlayer2(x)\n\u001b[0;32m--> 567\u001b[0m     x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlayer3\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    568\u001b[0m     x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlayer4(x)\n\u001b[1;32m    569\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m x\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torch/nn/modules/module.py:1518\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1516\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1518\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torch/nn/modules/module.py:1527\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1522\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1523\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1524\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1525\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1526\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1527\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1529\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1530\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torch/nn/modules/container.py:215\u001b[0m, in \u001b[0;36mSequential.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    213\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m):\n\u001b[1;32m    214\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m module \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m:\n\u001b[0;32m--> 215\u001b[0m         \u001b[38;5;28minput\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[43mmodule\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m    216\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28minput\u001b[39m\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torch/nn/modules/module.py:1518\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1516\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1518\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torch/nn/modules/module.py:1527\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1522\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1523\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1524\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1525\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1526\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1527\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1529\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1530\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/timm/models/resnet.py:221\u001b[0m, in \u001b[0;36mBottleneck.forward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m    218\u001b[0m x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbn1(x)\n\u001b[1;32m    219\u001b[0m x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mact1(x)\n\u001b[0;32m--> 221\u001b[0m x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconv2\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    222\u001b[0m x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbn2(x)\n\u001b[1;32m    223\u001b[0m x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdrop_block(x)\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torch/nn/modules/module.py:1518\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1516\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1518\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torch/nn/modules/module.py:1527\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1522\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1523\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1524\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1525\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1526\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1527\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1529\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1530\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torch/nn/modules/conv.py:460\u001b[0m, in \u001b[0;36mConv2d.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    459\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m: Tensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tensor:\n\u001b[0;32m--> 460\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_conv_forward\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbias\u001b[49m\u001b[43m)\u001b[49m\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torch/nn/modules/conv.py:456\u001b[0m, in \u001b[0;36mConv2d._conv_forward\u001b[0;34m(self, input, weight, bias)\u001b[0m\n\u001b[1;32m    452\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpadding_mode \u001b[38;5;241m!=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mzeros\u001b[39m\u001b[38;5;124m'\u001b[39m:\n\u001b[1;32m    453\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m F\u001b[38;5;241m.\u001b[39mconv2d(F\u001b[38;5;241m.\u001b[39mpad(\u001b[38;5;28minput\u001b[39m, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reversed_padding_repeated_twice, mode\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpadding_mode),\n\u001b[1;32m    454\u001b[0m                     weight, bias, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstride,\n\u001b[1;32m    455\u001b[0m                     _pair(\u001b[38;5;241m0\u001b[39m), \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdilation, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgroups)\n\u001b[0;32m--> 456\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconv2d\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbias\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstride\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    457\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpadding\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdilation\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgroups\u001b[49m\u001b[43m)\u001b[49m\n","\u001b[0;31mKeyboardInterrupt\u001b[0m: "]}],"source":["for fold, (train_index, valid_index) in enumerate(skf.split(X, y)):\n","    print(f\"Fold {fold + 1}/{n_splits}\")\n","\n","    # Split data into train and validation sets\n","    train_dataset = Subset(dataset, train_index)\n","    valid_dataset = Subset(dataset, valid_index)\n","\n","    # DataLoader 정의\n","    train_loader = DataLoader(\n","        train_dataset,\n","        batch_size=BATCH_SIZE,\n","        shuffle=True,\n","        num_workers=num_workers,\n","        pin_memory=True,\n","        drop_last=False\n","    )\n","    valid_loader = DataLoader(\n","        valid_dataset,\n","        batch_size=BATCH_SIZE,\n","        shuffle=False,\n","        num_workers=0,\n","        pin_memory=True\n","    )\n","\n","    # Initialize model for each fold\n","    model = timm.create_model(\n","        model_name,\n","        pretrained=True,\n","        num_classes=17\n","    ).to(device)\n","    loss_fn = nn.CrossEntropyLoss()\n","    optimizer = Adam(model.parameters(), lr=LR)\n","\n","    # Train the model for each fold\n","    for epoch in range(EPOCHS): #EPOCHS\n","        print(f\"Epoch {epoch + 1}/{EPOCHS}\")\n","\n","        # Train one epoch\n","        train_ret = train_one_epoch(train_loader, model, optimizer, loss_fn, device=device)\n","\n","        # Log train results\n","        train_log = \"\"\n","        for k, v in train_ret.items():\n","            train_log += f\"{k}: {v:.4f}\\n\"\n","        print(train_log)\n","\n","        # Store train results\n","        results[\"train_loss\"].append(train_ret[\"train_loss\"])\n","        results[\"train_acc\"].append(train_ret[\"train_acc\"])\n","        results[\"train_f1\"].append(train_ret[\"train_f1\"])\n","\n","# Print overall results\n","print(\"Overall Results:\")\n","for key, value in results.items():\n","    print(f\"{key}: {sum(value) / len(value):.4f}\")"]},{"attachments":{},"cell_type":"markdown","metadata":{"id":"lkwxRXoBpbaX"},"source":["# 6. Inference & Save File\n","* 테스트 이미지에 대한 추론을 진행하고, 결과 파일을 저장합니다."]},{"cell_type":"code","execution_count":24,"metadata":{},"outputs":[],"source":["import pickle\n","# 저장된 모델을 불러옵니다.\n","with open('saved_model_sanghyuk_32_rotation_10_eda_3.pkl', 'rb') as f:\n","    model = pickle.load(f)"]},{"cell_type":"code","execution_count":25,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":12776,"status":"ok","timestamp":1700315185336,"user":{"displayName":"Ynot(송원호)","userId":"16271863862696372773"},"user_tz":-540},"id":"uRYe6jlPU_Om","outputId":"2a08690c-9ffe-418d-8679-eb9280147110"},"outputs":[{"name":"stderr","output_type":"stream","text":["100%|██████████| 99/99 [00:15<00:00,  6.38it/s]\n"]}],"source":["preds_list = []\n","\n","model.eval()\n","for image, _ in tqdm(tst_loader):\n","    image = image.to(device)\n","\n","    with torch.no_grad():\n","        preds = model(image)\n","    preds_list.extend(preds.argmax(dim=1).detach().cpu().numpy())"]},{"cell_type":"code","execution_count":26,"metadata":{"executionInfo":{"elapsed":282,"status":"ok","timestamp":1700315216829,"user":{"displayName":"Ynot(송원호)","userId":"16271863862696372773"},"user_tz":-540},"id":"aClN7Qi7VZoh"},"outputs":[],"source":["pred_df = pd.DataFrame(tst_dataset.df, columns=['ID', 'target'])\n","pred_df['target'] = preds_list"]},{"cell_type":"code","execution_count":27,"metadata":{"executionInfo":{"elapsed":1,"status":"ok","timestamp":1700315238836,"user":{"displayName":"Ynot(송원호)","userId":"16271863862696372773"},"user_tz":-540},"id":"VDBXQqAzVvLY"},"outputs":[],"source":["sample_submission_df = pd.read_csv(\"data/sample_submission.csv\")\n","assert (sample_submission_df['ID'] == pred_df['ID']).all()"]},{"cell_type":"code","execution_count":28,"metadata":{"executionInfo":{"elapsed":317,"status":"ok","timestamp":1700315244710,"user":{"displayName":"Ynot(송원호)","userId":"16271863862696372773"},"user_tz":-540},"id":"ePx2vCELVnuS"},"outputs":[],"source":["pred_df.to_csv(\"./pred/pred_sangmin_6.csv\", index=False)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":206},"executionInfo":{"elapsed":353,"status":"ok","timestamp":1700315247734,"user":{"displayName":"Ynot(송원호)","userId":"16271863862696372773"},"user_tz":-540},"id":"9yMO8s6GqAwZ","outputId":"9a30616f-f0ea-439f-a906-dd806737ce00"},"outputs":[{"data":{"text/html":["\n","  <div id=\"df-4409bdf5-2a00-47fd-a06b-ceecd189d672\" class=\"colab-df-container\">\n","    <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>ID</th>\n","      <th>target</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>0008fdb22ddce0ce.jpg</td>\n","      <td>2</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>00091bffdffd83de.jpg</td>\n","      <td>6</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>00396fbc1f6cc21d.jpg</td>\n","      <td>5</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>00471f8038d9c4b6.jpg</td>\n","      <td>16</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>00901f504008d884.jpg</td>\n","      <td>2</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>\n","    <div class=\"colab-df-buttons\">\n","\n","  <div class=\"colab-df-container\">\n","    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-4409bdf5-2a00-47fd-a06b-ceecd189d672')\"\n","            title=\"Convert this dataframe to an interactive table.\"\n","            style=\"display:none;\">\n","\n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n","    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n","  </svg>\n","    </button>\n","\n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    .colab-df-buttons div {\n","      margin-bottom: 4px;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","    <script>\n","      const buttonEl =\n","        document.querySelector('#df-4409bdf5-2a00-47fd-a06b-ceecd189d672 button.colab-df-convert');\n","      buttonEl.style.display =\n","        google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","      async function convertToInteractive(key) {\n","        const element = document.querySelector('#df-4409bdf5-2a00-47fd-a06b-ceecd189d672');\n","        const dataTable =\n","          await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                    [key], {});\n","        if (!dataTable) return;\n","\n","        const docLinkHtml = 'Like what you see? Visit the ' +\n","          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","          + ' to learn more about interactive tables.';\n","        element.innerHTML = '';\n","        dataTable['output_type'] = 'display_data';\n","        await google.colab.output.renderOutput(dataTable, element);\n","        const docLink = document.createElement('div');\n","        docLink.innerHTML = docLinkHtml;\n","        element.appendChild(docLink);\n","      }\n","    </script>\n","  </div>\n","\n","\n","<div id=\"df-54d3ef38-66cc-4a14-ac38-d6291f693a97\">\n","  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-54d3ef38-66cc-4a14-ac38-d6291f693a97')\"\n","            title=\"Suggest charts\"\n","            style=\"display:none;\">\n","\n","<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","     width=\"24px\">\n","    <g>\n","        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n","    </g>\n","</svg>\n","  </button>\n","\n","<style>\n","  .colab-df-quickchart {\n","      --bg-color: #E8F0FE;\n","      --fill-color: #1967D2;\n","      --hover-bg-color: #E2EBFA;\n","      --hover-fill-color: #174EA6;\n","      --disabled-fill-color: #AAA;\n","      --disabled-bg-color: #DDD;\n","  }\n","\n","  [theme=dark] .colab-df-quickchart {\n","      --bg-color: #3B4455;\n","      --fill-color: #D2E3FC;\n","      --hover-bg-color: #434B5C;\n","      --hover-fill-color: #FFFFFF;\n","      --disabled-bg-color: #3B4455;\n","      --disabled-fill-color: #666;\n","  }\n","\n","  .colab-df-quickchart {\n","    background-color: var(--bg-color);\n","    border: none;\n","    border-radius: 50%;\n","    cursor: pointer;\n","    display: none;\n","    fill: var(--fill-color);\n","    height: 32px;\n","    padding: 0;\n","    width: 32px;\n","  }\n","\n","  .colab-df-quickchart:hover {\n","    background-color: var(--hover-bg-color);\n","    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n","    fill: var(--button-hover-fill-color);\n","  }\n","\n","  .colab-df-quickchart-complete:disabled,\n","  .colab-df-quickchart-complete:disabled:hover {\n","    background-color: var(--disabled-bg-color);\n","    fill: var(--disabled-fill-color);\n","    box-shadow: none;\n","  }\n","\n","  .colab-df-spinner {\n","    border: 2px solid var(--fill-color);\n","    border-color: transparent;\n","    border-bottom-color: var(--fill-color);\n","    animation:\n","      spin 1s steps(1) infinite;\n","  }\n","\n","  @keyframes spin {\n","    0% {\n","      border-color: transparent;\n","      border-bottom-color: var(--fill-color);\n","      border-left-color: var(--fill-color);\n","    }\n","    20% {\n","      border-color: transparent;\n","      border-left-color: var(--fill-color);\n","      border-top-color: var(--fill-color);\n","    }\n","    30% {\n","      border-color: transparent;\n","      border-left-color: var(--fill-color);\n","      border-top-color: var(--fill-color);\n","      border-right-color: var(--fill-color);\n","    }\n","    40% {\n","      border-color: transparent;\n","      border-right-color: var(--fill-color);\n","      border-top-color: var(--fill-color);\n","    }\n","    60% {\n","      border-color: transparent;\n","      border-right-color: var(--fill-color);\n","    }\n","    80% {\n","      border-color: transparent;\n","      border-right-color: var(--fill-color);\n","      border-bottom-color: var(--fill-color);\n","    }\n","    90% {\n","      border-color: transparent;\n","      border-bottom-color: var(--fill-color);\n","    }\n","  }\n","</style>\n","\n","  <script>\n","    async function quickchart(key) {\n","      const quickchartButtonEl =\n","        document.querySelector('#' + key + ' button');\n","      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n","      quickchartButtonEl.classList.add('colab-df-spinner');\n","      try {\n","        const charts = await google.colab.kernel.invokeFunction(\n","            'suggestCharts', [key], {});\n","      } catch (error) {\n","        console.error('Error during call to suggestCharts:', error);\n","      }\n","      quickchartButtonEl.classList.remove('colab-df-spinner');\n","      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n","    }\n","    (() => {\n","      let quickchartButtonEl =\n","        document.querySelector('#df-54d3ef38-66cc-4a14-ac38-d6291f693a97 button');\n","      quickchartButtonEl.style.display =\n","        google.colab.kernel.accessAllowed ? 'block' : 'none';\n","    })();\n","  </script>\n","</div>\n","    </div>\n","  </div>\n"],"text/plain":["                     ID  target\n","0  0008fdb22ddce0ce.jpg       2\n","1  00091bffdffd83de.jpg       6\n","2  00396fbc1f6cc21d.jpg       5\n","3  00471f8038d9c4b6.jpg      16\n","4  00901f504008d884.jpg       2"]},"execution_count":38,"metadata":{},"output_type":"execute_result"}],"source":["pred_df.head()"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":[]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":[]},{"cell_type":"markdown","metadata":{},"source":["# confusion_matrix"]},{"cell_type":"code","execution_count":16,"metadata":{},"outputs":[],"source":["# val image 변환을 위한 transform 코드\n","val_transform = A.Compose([\n","    A.Resize(height=img_size, width=img_size),\n","    A.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n","    ToTensorV2(),\n","])"]},{"cell_type":"code","execution_count":17,"metadata":{},"outputs":[],"source":["# val _ data만듬\n","val_dataset = ImageDataset(\n","    \"data/split_val.csv\",\n","    \"data/split_val_data/\",\n","    transform = val_transform\n",")"]},{"cell_type":"code","execution_count":18,"metadata":{},"outputs":[],"source":["val_loader = DataLoader(\n","    val_dataset,\n","    batch_size=BATCH_SIZE,\n","    shuffle=True,\n","    num_workers=num_workers,\n","    pin_memory=True,\n","    drop_last=False\n",")"]},{"cell_type":"code","execution_count":19,"metadata":{},"outputs":[{"name":"stderr","output_type":"stream","text":["100%|██████████| 364/364 [00:47<00:00,  7.70it/s]"]},{"name":"stdout","output_type":"stream","text":["perfomance \n","               precision    recall  f1-score   support\n","\n","           0      1.000     1.000     1.000       740\n","           1      1.000     1.000     1.000       340\n","           2      1.000     1.000     1.000       740\n","           3      1.000     1.000     1.000       740\n","           4      1.000     1.000     1.000       740\n","           5      1.000     1.000     1.000       740\n","           6      1.000     1.000     1.000       740\n","           7      1.000     1.000     1.000       740\n","           8      1.000     1.000     1.000       740\n","           9      1.000     1.000     1.000       740\n","          10      1.000     1.000     1.000       740\n","          11      1.000     1.000     1.000       740\n","          12      1.000     1.000     1.000       740\n","          13      1.000     1.000     1.000       547\n","          14      1.000     1.000     1.000       370\n","          15      1.000     1.000     1.000       740\n","          16      1.000     1.000     1.000       740\n","\n","    accuracy                          1.000     11617\n","   macro avg      1.000     1.000     1.000     11617\n","weighted avg      1.000     1.000     1.000     11617\n","\n"]},{"name":"stderr","output_type":"stream","text":["\n"]}],"source":["# confusion_matrix\n","\n","from sklearn import metrics\n","import matplotlib.pyplot as plt\n","\n","import pickle\n","# 저장된 모델을 불러옵니다.\n","with open('saved_model_rotation_10.pkl', 'rb') as f:\n","    model = pickle.load(f)\n","\n","model = model.to(device)\n","model.eval()\n","\n","y_pred = []\n","y_true = []\n","\n","class_names = {\n","    0: 'account_number',\n","    1: 'application_for_payment_of_pregnancy_medical_expenses',\n","    2: 'car_dashboard',\n","    3: 'confirmation_of_admission_and_discharge',\n","    4: 'diagnosis',\n","    5: 'driver_lisence',\n","    6: 'medical_bill_receipts',\n","    7: 'medical_outpatient_certificate',\n","    8: 'national_id_card',\n","    9: 'passport',\n","    10: 'payment_confirmation',\n","    11: 'pharmaceutical_receipt',\n","    12: 'prescription',\n","    13: 'resume',\n","    14: 'statement_of_opinion',\n","    15: 'vehicle_registration_certificate',\n","    16: 'vehicle_registration_plate'\n","}\n","\n","for batch in tqdm(val_loader):\n","    with torch.no_grad():\n","        inputs, targets = batch\n","\n","        inputs = inputs.to(device)\n","        targets = targets.to(device)\n","\n","        outputs = model(inputs)\n","    y_pred.extend(torch.max(outputs, dim=1)[1].detach().cpu().numpy())\n","    y_true.extend(targets.detach().cpu().numpy())\n","\n","performance = metrics.classification_report(y_true, y_pred, digits=3) # digits 소수점 3자리\n","confusion_matrix = metrics.confusion_matrix(y_true, y_pred)\n","\n","print(f\"perfomance \\n {performance}\")"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["display_confusionmap = metrics.ConfusionMatrixDisplay(confusion_matrix=confusion_matrix, display_labels=list(range(len(class_names))))\n","\n","display_confusionmap.plot()\n","fig = display_confusionmap.ax_.get_figure()\n","fig.set_figwidth(len(class_names))\n","fig.set_figheight(len(class_names))\n","plt.savefig(\"validation_confusion_metrix.jpg\") # 그림 저장\n","plt.show"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":[]},{"cell_type":"markdown","metadata":{},"source":["총 7개에서 모델 학습시 영향이 큰 경향 \n","       precision    recall  f1-score   support\n","1번 : 1: 'application_for_payment_of_pregnancy_medical_expenses', 임산부 신청서 \n","1      0.976     1.000     0.988      1343\n","3번 : 3: 'confirmation_of_admission_and_discharge', 입퇴원 확인서\n"," 3      0.767     0.901     0.829      2920\n","4번 : 4: 'diagnosis', 진단서\n","4      0.975     0.923     0.948      2920\n","7번 : 7: 'medical_outpatient_certificate',의료 납입 확인서\n","7      0.886     0.756     0.816      2920\n","12번 : 12: 'prescription', 처방전\n","12      0.979     0.996     0.987      2920\n","13번 : 13: 'resume', 이력서\n","13      0.970     0.985     0.977      2160\n","14번 : 14: 'statement_of_opinion', 소견서 \n","14      0.848     0.838     0.843      1460"]}],"metadata":{"accelerator":"GPU","colab":{"provenance":[]},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.13"}},"nbformat":4,"nbformat_minor":0}
